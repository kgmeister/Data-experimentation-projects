import os, re, time, requests
from typing import Dict, List, Optional, Tuple

_NUM_URL_KEY = re.compile(r"^LLM_(\d+)_API_URL$", re.I)

def _parse_status_list(spec: str) -> List[Tuple[int, int]]:
    out = []
    for part in (spec or "").split(","):
        part = part.strip()
        if not part: continue
        if "-" in part:
            a, b = part.split("-", 1); out.append((int(a), int(b)))
        else:
            v = int(part); out.append((v, v))
    return out

def _status_matches(ranges: List[Tuple[int, int]], status: int) -> bool:
    return any(lo <= status <= hi for lo, hi in ranges)

def _parse_extra_headers(raw: Optional[str]) -> Dict[str, str]:
    headers = {}
    if not raw: return headers
    for p in [p.strip() for p in raw.split(";") if p.strip()]:
        if ":" in p:
            k, v = p.split(":", 1)
            headers[k.strip()] = v.strip()
    return headers

def _auth_headers(auth_type: str, key: str) -> Dict[str, str]:
    # bearer -> Authorization, api-key -> api-key, header:Name -> Name
    if auth_type == "bearer":
        return {"Authorization": f"Bearer {key}"}
    if auth_type == "api-key":
        return {"api-key": key}
    if auth_type.startswith("header:"):
        name = auth_type.split(":", 1)[1].strip() or "Authorization"
        return {name: key}
    return {"Authorization": f"Bearer {key}"}  # default

def _discover_indices(env: Dict[str, str]) -> List[int]:
    nums = {int(m.group(1)) for k in env.keys() for m in [_NUM_URL_KEY.match(k)] if m}
    if (env.get("API_URL") or env.get("LLM_API_URL")) and (env.get("API_KEY") or env.get("LLM_API_KEY")):
        nums.add(0)
    return sorted(nums)

def _provider_from_env(env: Dict[str, str], n: int) -> Optional[Dict[str, str]]:
    if n == 0:
        api_url = env.get("LLM_API_URL") or env.get("API_URL")
        api_key = env.get("LLM_API_KEY") or env.get("API_KEY")
        model   = (env.get("LLM_MODEL") or env.get("MODEL") or "").strip()
        auth    = (env.get("LLM_AUTH_TYPE") or "bearer").strip().lower()
        extra   = env.get("LLM_HEADERS") or ""
    else:
        p = f"LLM_{n}_"
        api_url = env.get(p + "API_URL")
        api_key = env.get(p + "API_KEY")
        model   = (env.get(p + "MODEL") or "").strip()
        auth    = (env.get(p + "AUTH_TYPE") or "bearer").strip().lower()
        extra   = env.get(p + "HEADERS") or ""
    if not (api_url and api_key):
        return None
    return {"idx": n, "name": f"LLM_{n}", "api_url": api_url.strip(), "api_key": api_key.strip(),
            "model": model, "auth_type": auth, "extra_headers": extra}

def iter_llm_providers() -> List[Dict[str, str]]:
    env = os.environ
    out = []
    for n in _discover_indices(env):
        p = _provider_from_env(env, n)
        if p: out.append(p)
    return out

def _build_request(provider: Dict[str, str], messages, temperature: float, max_tokens: Optional[int]):
    """Return (url, headers, payload) â€” always brand-new objects per call."""
    url = provider["api_url"]
    headers = {"Content-Type": "application/json"}
    headers.update(_auth_headers(provider["auth_type"], provider["api_key"]))
    headers.update(_parse_extra_headers(provider["extra_headers"]))

    payload = {"messages": messages, "temperature": temperature}
    if provider["model"]:
        payload["model"] = provider["model"]
    if max_tokens is not None:
        payload["max_tokens"] = max_tokens
    return url, headers, payload

def chat_with_failover(messages, temperature: Optional[float] = None, max_tokens: Optional[int] = None) -> str:
    timeout  = float(os.getenv("LLM_TIMEOUT_SECONDS", "25"))
    retries  = int(os.getenv("LLM_RETRIES", "2"))
    backoff  = float(os.getenv("LLM_BACKOFF_SECONDS", "1.2"))
    failover_ranges = _parse_status_list(os.getenv("LLM_FAILOVER_ON_STATUS", "500-599"))

    if temperature is None:
        temperature = float(os.getenv("LLM_DEFAULT_TEMPERATURE", "0.2"))
    if max_tokens is None:
        mt = os.getenv("LLM_DEFAULT_MAX_TOKENS")
        max_tokens = int(mt) if mt else None

    last_err: Optional[Exception] = None

    for p in iter_llm_providers():
        for attempt in range(retries + 1):
            try:
                url, headers, payload = _build_request(p, messages, temperature, max_tokens)
                r = requests.post(url, json=payload, headers=headers, timeout=timeout)

                if r.status_code == 200:
                    data = r.json()
                    choices = data.get("choices") or []
                    if choices and "message" in choices[0] and "content" in choices[0]["message"]:
                        return choices[0]["message"]["content"]
                    if choices and "text" in choices[0]:
                        return choices[0]["text"]
                    raise RuntimeError(f"{p['name']} unexpected response: {str(data)[:400]}")

                if _status_matches(failover_ranges, r.status_code):
                    last_err = RuntimeError(f"{p['name']} HTTP {r.status_code}: {r.text[:400]}")
                    break  # immediate failover
                else:
                    last_err = RuntimeError(f"{p['name']} HTTP {r.status_code}: {r.text[:400]}")
                    time.sleep(backoff * (attempt + 1))  # retry same provider

            except requests.RequestException as e:
                last_err = e
                time.sleep(backoff * (attempt + 1))  # retry same provider
        # next provider

    raise last_err or RuntimeError("All LLM providers failed")
